\section{Introduction}\label{section:introduction}

Text clustering is a problem that is relevant across a number of domains, including news, social media, health, finance, and more.
While there exist a number of traditional clustering methods that work well for textual data, many rely on a shared vocabulary (i.e. TF-IDF~\cite{salton-buckley}).
Clustering in a cross-lingual setting is particularly challenging, since there may not be a shared vocabulary or script across the languages, and so this setting has garnered recent attention~\cite{Schneider2023}.

Recent approaches to cross-lingual text clustering have found some success by leveraging latent embedding space representations from neural models trained to perform machine translation~\cite{Schw18, Hong17,Pire19, Amma18}.
More recently Large Language Models (LLMs) themselves have been used to do text clustering in zero-shot or few-shot prompting approaches~\cite{Zhang2023clusterllm, Viswanathan2024}.
The benefit of using LLMs to perform or aid in cross-lingual text clustering is that they contain powerful word models for the languages they were exposed to during training over massive amounts of textual data.
Further, LLMs are flexible and capable of generating text on demand across a variety of languages, including ones with different vocabularies and scripts, making them potentially useful for the task of cross-lingual text clustering.

Despite these apparent advantages, much of the recent work in clustering text documents using LLMs has focused on clustering short documents, such as social media posts, in a single language, such as English.
The challenge remains to automatically cluster longer documents, such as publications or news articles, written in different languages, which is relevant in a number of domains.

In this paper, we explore the viability of applying LLMs to the problem of cross-lingual text clustering by performing a series of experiments using data from the news domain in an online clustering setting.
We build on previous work in cross-lingual clustering in the news domain~\cite{Schneider2023} by testing whether LLMs can provide value beyond traditional clustering by extracting key phrases and using them to determine which cluster a new article belongs in.
Further, we introduce key metadata fields, including the time of publication and location associated with each article, to aid in clustering and measure how well LLMs are able to account for these pieces of information when deciding which cluster an article belongs in.
We compare the cluster assignments several LLMs produce in a zero-shot setting against a more traditional online clustering method that uses machine translation followed by TF-IDF to cluster documents based on their content and time of publication.

We find that in the single-language setting, LLMs produced cluster assignments that had lower \ac{NMI} than the traditional baseline method.
Further, providing the LLMs with article title, time of publication, and location led to worse cluster assignments that using the text alone.
In the cross-lingual setting, we found that both the baseline method and the LLMs tended to assign articles to clusters based on the language of the document, rather than its content.
Our results indicate that further work is needed before LLMs can be used to reliably cluster large documents, especially ones spanning multiple languages.
In addition to our findings, we provide a hand-labeled dataset of English articles and an unlabeled dataset of articles spanning multiple languages to enable future testing of newer LLMs and other prompting strategies and clustering methods on the task of cross-lingual clustering of long documents.

The rest of this paper is organized as follows.
In section \ref{section:data} we describe the news datasets that we create to evaluate mono-lingual and cross-lingual clustering ability.
Then, we describe our experimental setup in section \ref{section:method}, and our results in section \ref{section:results}.
Next, we discuss the significance of our findings in section \ref{section:discussion} and summarize related work in LLM and neural clustering in section \ref{section:related_work}.
Finally, we discuss future work and conclude in section \ref{section:conclusion}.